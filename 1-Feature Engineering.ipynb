{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:33.967028Z",
     "start_time": "2025-10-30T05:17:33.952144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "import jieba\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer"
   ],
   "id": "359b8894ee8aca69",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1 特征中含有字符串的时候（当成类别），如何做特征提取",
   "id": "f2a7887b5fb5f35f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.035049Z",
     "start_time": "2025-10-30T05:17:33.993929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dictvec():\n",
    "    \"\"\"\n",
    "    字典数据提取\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # 实例化\n",
    "    # sparse改为True，输出的是每个不为零位置的坐标，稀疏矩阵可以节省存储空间\n",
    "    # 矩阵中存在大量的0，sparse存储只记录非零位置，节省空间的作用\n",
    "    #Vectorizer中文含义是矢量器的含义\n",
    "    dict1 = DictVectorizer(sparse=True)  # 把sparse设置为True，输出的是稀疏矩阵\n",
    "    # 每个样本是一个字典，字典的key是特征名，value是特征值，有三个样本\n",
    "    #调用fit_transform方法，把字典转换为稀疏矩阵\n",
    "    data = dict1.fit_transform([{'city': '北京', 'temperature': 100},\n",
    "                                {'city': '上海', 'temperature': 60},\n",
    "                                {'city': '深圳', 'temperature': 30}])\n",
    "    print(data)\n",
    "    print('-' * 50)\n",
    "    # 字典中一些类别数据，分别进行转换成特征\n",
    "    print(dict1.get_feature_names_out())\n",
    "    print(\"-\" * 50)\n",
    "    print(dict1.inverse_transform(data))  # 去看每个特征代表的含义，逆转回去\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "dictvec()"
   ],
   "id": "ef3c6870550da5a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 6 stored elements and shape (3, 4)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t100.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 3)\t60.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 3)\t30.0\n",
      "--------------------------------------------------\n",
      "['city=上海' 'city=北京' 'city=深圳' 'temperature']\n",
      "--------------------------------------------------\n",
      "[{'city=北京': np.float64(1.0), 'temperature': np.float64(100.0)}, {'city=上海': np.float64(1.0), 'temperature': np.float64(60.0)}, {'city=深圳': np.float64(1.0), 'temperature': np.float64(30.0)}]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 一段英文文本如何变为数值类型",
   "id": "2a7486ea92b0cd37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.054066Z",
     "start_time": "2025-10-30T05:17:34.045366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def couvec():\n",
    "    \"\"\"\n",
    "    实例化CountVectorizer\n",
    "    max_df,min_df整数，指每个词的所有文档中出现的最大、最小次数，超过这个次数的词会被过滤掉\n",
    "    max_df,min_df小数(0-1之间的)：某个词的出现的次数占所有文档的比例，超过这个比例的词会被过滤掉\n",
    "    min_df=2，过滤掉出现次数小于2的词\n",
    "    默认会去除单个字母的单词，默认认为这个词对整个样本没有影响，认为其没有语义\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    vector = CountVectorizer(min_df=2)\n",
    "\n",
    "    # 调用fit_transform方法，输入并转换数据,把文本转换为稀疏矩阵\n",
    "\n",
    "    res = vector.fit_transform(\n",
    "        [\"life is short, i like python life\",\n",
    "        \"life is too long, i dislike python\",\n",
    "        \"life is short\"])\n",
    "\n",
    "    # 打印结果，把每个分词都分离了\n",
    "    print(vector.get_feature_names_out())\n",
    "    print('-'*50)\n",
    "    print(res)\n",
    "    print('-'*50)\n",
    "    print(type(res))\n",
    "    # 对照feature_names，标记每个词出现的次数\n",
    "    print('-'*50)\n",
    "    print(res.toarray()) #稀疏矩阵转换为数组\n",
    "    print('-'*50)\n",
    "    #拿每个样本里的特征进行显示\n",
    "    print(vector.inverse_transform(res))\n",
    "\n",
    "couvec()"
   ],
   "id": "60e8a53aa47392ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is' 'life' 'python' 'short']\n",
      "--------------------------------------------------\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 10 stored elements and shape (3, 4)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t2\n",
      "  (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "--------------------------------------------------\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "--------------------------------------------------\n",
      "[[1 2 1 1]\n",
      " [1 1 1 0]\n",
      " [1 1 0 1]]\n",
      "--------------------------------------------------\n",
      "[array(['life', 'is', 'short', 'python'], dtype='<U6'), array(['life', 'is', 'python'], dtype='<U6'), array(['life', 'is', 'short'], dtype='<U6')]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 一段汉字文本如何数值化，对于汉字不能用空格来分割",
   "id": "74eb52bbb17cf9a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.072729Z",
     "start_time": "2025-10-30T05:17:34.065599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def countvec():\n",
    "    \"\"\"\n",
    "    对文本进行特征值化，单个汉字单个字母不统计，因为单个汉字字母没有意义\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    cv = CountVectorizer()\n",
    "    \n",
    "    data = cv.fit_transform([\"人生苦短，我 喜欢 python python\", \"人生漫长，不用 python\"])\n",
    "    \n",
    "    print(cv.get_feature_names_out())\n",
    "    print('-' * 50)\n",
    "    print(data) # 稀疏存储，只记录非零位置\n",
    "    print('-' * 50)\n",
    "    print(data.toarray())\n",
    "    \n",
    "    return None\n",
    "\n",
    "countvec()"
   ],
   "id": "662118544f95f7a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python' '不用' '人生漫长' '人生苦短' '喜欢']\n",
      "--------------------------------------------------\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 6 stored elements and shape (2, 5)>\n",
      "  Coords\tValues\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 0)\t2\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n",
      "--------------------------------------------------\n",
      "[[2 0 0 1 1]\n",
      " [1 1 1 0 0]]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.3 掌握如何对中文进行分词",
   "id": "cb90c533f7b3b01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.095609Z",
     "start_time": "2025-10-30T05:17:34.075448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cutword():\n",
    "    \"\"\"\n",
    "    通过jieba对中文进行分词\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    con1 = jieba.cut(\"今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上。所以每个人不要放弃今天。\")\n",
    "    \n",
    "    con2 = jieba.cut(\"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\")\n",
    "    \n",
    "    con3 = jieba.cut(\"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\")\n",
    "    \n",
    "    #转换成列表\n",
    "    print(type(con1))\n",
    "    print('-' * 50)\n",
    "    #把生成器转换成列表\n",
    "    content1 = list(con1)\n",
    "    content2 = list(con2)\n",
    "    content3 = list(con3)\n",
    "    print(content1)\n",
    "    print(content2)\n",
    "    print(content3)\n",
    "    # 把列表转换成字符串，每个词之间用空格隔开\n",
    "    print('-' * 50)\n",
    "    c1 = ' '.join(content1)\n",
    "    c2 = ' '.join(content2)\n",
    "    c3 = ' '.join(content3)\n",
    "    \n",
    "    return c1, c2, c3\n",
    "\n",
    "def hanzivec():\n",
    "    \"\"\"\n",
    "    中文特征值化\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    c1, c2, c3 = cutword() # jieba分词好的中文文本\n",
    "    print('-' * 50)\n",
    "    print(c1)\n",
    "    print(c2)\n",
    "    print(c3)\n",
    "    print('-' * 50)\n",
    "    \n",
    "    cv = CountVectorizer()\n",
    "    \n",
    "    data = cv.fit_transform([c1, c2, c3])\n",
    "    \n",
    "    print(cv.get_feature_names_out())\n",
    "    \n",
    "    print(data.toarray())\n",
    "    \n",
    "    return None\n",
    "\n",
    "# cutword()\n",
    "hanzivec()"
   ],
   "id": "48bc333698e9627",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "--------------------------------------------------\n",
      "['今天', '很', '残酷', '，', '明天', '更', '残酷', '，', '后天', '很', '美好', '，', '但', '绝对', '大部分', '是', '死', '在', '明天', '晚上', '。', '所以', '每个', '人', '不要', '放弃', '今天', '。']\n",
      "['我们', '看到', '的', '从', '很', '远', '星系', '来', '的', '光是在', '几百万年', '之前', '发出', '的', '，', '这样', '当', '我们', '看到', '宇宙', '时', '，', '我们', '是', '在', '看', '它', '的', '过去', '。']\n",
      "['如果', '只用', '一种', '方式', '了解', '某样', '事物', '，', '你', '就', '不会', '真正', '了解', '它', '。', '了解', '事物', '真正', '含义', '的', '秘密', '取决于', '如何', '将', '其', '与', '我们', '所', '了解', '的', '事物', '相', '联系', '。']\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 。 所以 每个 人 不要 放弃 今天 。\n",
      "我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。\n",
      "如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。\n",
      "--------------------------------------------------\n",
      "['一种' '不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '这样']\n",
      "[[0 0 1 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 2 0 1 0 2 1 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 1]\n",
      " [1 1 0 0 4 3 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 2 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.4 tf-idf",
   "id": "c12c1ffd4b70437f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.117127Z",
     "start_time": "2025-10-30T05:17:34.108604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# smooth_idf布尔值，默认为True\n",
    "# 防止零分裂，比如训练集中有某个词，测试集中没有，就是生僻词，就会造成n(x)分母为零，log(n/n(x)),从而出现零分裂\n",
    "\n",
    "def tfidfvec():\n",
    "    \"\"\"\n",
    "    中文特征值化，计算tfidf值\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    c1, c2, c3 = cutword()\n",
    "    \n",
    "    print(c1, c2, c3)\n",
    "    # print(type([c1, c2, c3]))\n",
    "    tf = TfidfVectorizer(smooth_idf=True)\n",
    "    \n",
    "    data = tf.fit_transform([c1, c2, c3])\n",
    "    \n",
    "    print(tf.get_feature_names_out())\n",
    "    print('-' * 50)\n",
    "    print(type(data))\n",
    "    print('-' * 50)\n",
    "    print(data.toarray())\n",
    "    \n",
    "    return None\n",
    "\n",
    "tfidfvec()"
   ],
   "id": "6d3ffca25e9b473a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "--------------------------------------------------\n",
      "['今天', '很', '残酷', '，', '明天', '更', '残酷', '，', '后天', '很', '美好', '，', '但', '绝对', '大部分', '是', '死', '在', '明天', '晚上', '。', '所以', '每个', '人', '不要', '放弃', '今天', '。']\n",
      "['我们', '看到', '的', '从', '很', '远', '星系', '来', '的', '光是在', '几百万年', '之前', '发出', '的', '，', '这样', '当', '我们', '看到', '宇宙', '时', '，', '我们', '是', '在', '看', '它', '的', '过去', '。']\n",
      "['如果', '只用', '一种', '方式', '了解', '某样', '事物', '，', '你', '就', '不会', '真正', '了解', '它', '。', '了解', '事物', '真正', '含义', '的', '秘密', '取决于', '如何', '将', '其', '与', '我们', '所', '了解', '的', '事物', '相', '联系', '。']\n",
      "--------------------------------------------------\n",
      "今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 。 所以 每个 人 不要 放弃 今天 。 我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。 如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。\n",
      "['一种' '不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '这样']\n",
      "--------------------------------------------------\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "--------------------------------------------------\n",
      "[[0.         0.         0.21821789 0.         0.         0.\n",
      "  0.43643578 0.         0.         0.         0.         0.\n",
      "  0.21821789 0.         0.21821789 0.         0.         0.\n",
      "  0.         0.21821789 0.21821789 0.         0.43643578 0.\n",
      "  0.21821789 0.         0.43643578 0.21821789 0.         0.\n",
      "  0.         0.21821789 0.21821789 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.2410822  0.         0.\n",
      "  0.         0.2410822  0.2410822  0.2410822  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.2410822\n",
      "  0.55004769 0.         0.         0.         0.         0.2410822\n",
      "  0.         0.         0.         0.         0.48216441 0.\n",
      "  0.         0.         0.         0.         0.2410822  0.2410822 ]\n",
      " [0.15698297 0.15698297 0.         0.         0.62793188 0.47094891\n",
      "  0.         0.         0.         0.         0.15698297 0.15698297\n",
      "  0.         0.15698297 0.         0.15698297 0.15698297 0.\n",
      "  0.1193896  0.         0.         0.15698297 0.         0.\n",
      "  0.         0.15698297 0.         0.         0.         0.31396594\n",
      "  0.15698297 0.         0.         0.15698297 0.         0.        ]]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 2 特征处理，不同的特征拉到同一个量纲"
   ],
   "id": "e7fefcca7a18ea08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.155985Z",
     "start_time": "2025-10-30T05:17:34.141846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mm():\n",
    "    \"\"\"\n",
    "    归一化处理\n",
    "    :return:None \n",
    "    \"\"\"\n",
    "    # 归一化缺点 容易受极值影响\n",
    "    # feature_range代表特征值的范围，一般设置为(0,1),或者(-1,1),默认是(0,1)\n",
    "    mm = MinMaxScaler(feature_range=(0,1))\n",
    "    \n",
    "    data = mm.fit_transform([[90, 2, 10, 40], [60, 4, 15, 45], [75, 3, 13, 46]])\n",
    "    \n",
    "    print(data)\n",
    "    print('-' * 50)\n",
    "    out = mm.transform([[1, 2, 3, 4], [6, 5, 8, 7]])\n",
    "    print(out)\n",
    "    return None\n",
    "\n",
    "mm()"
   ],
   "id": "c5e94bd5c0a5f2c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         0.        ]\n",
      " [0.         1.         1.         0.83333333]\n",
      " [0.5        0.5        0.6        1.        ]]\n",
      "--------------------------------------------------\n",
      "[[-1.96666667  0.         -1.4        -6.        ]\n",
      " [-1.8         1.5        -0.4        -5.5       ]]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.172372Z",
     "start_time": "2025-10-30T05:17:34.160346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stand():\n",
    "    \"\"\"\n",
    "    标准化缩放，不是标准正态分布，只均值为0，方差为1的分布\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    std = StandardScaler()\n",
    "    data = std.fit_transform([[1., -1., 3.], [2., 4., 2.], [4., 6., -1.]])\n",
    "    \n",
    "    print(data)\n",
    "    print('-' * 50)\n",
    "    print(std.mean_)\n",
    "    print('-' * 50)\n",
    "    print(std.var_)\n",
    "    print(std.n_samples_seen_) # 样本数\n",
    "    return data\n",
    "\n",
    "data = stand()\n",
    "type(data)"
   ],
   "id": "cbaf536246ce5b97",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.06904497 -1.35873244  0.98058068]\n",
      " [-0.26726124  0.33968311  0.39223227]\n",
      " [ 1.33630621  1.01904933 -1.37281295]]\n",
      "--------------------------------------------------\n",
      "[2.33333333 3.         1.33333333]\n",
      "--------------------------------------------------\n",
      "[1.55555556 8.66666667 2.88888889]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.178700Z",
     "start_time": "2025-10-30T05:17:34.174347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "std1 = StandardScaler()\n",
    "# 为了证明上面输出的结果的均值是0的，方差为1\n",
    "data1 = std1.fit_transform(data)\n",
    "# 均值\n",
    "print(std1.mean_)\n",
    "# 方差\n",
    "print(std1.var_)"
   ],
   "id": "614b63fc06177f64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.48029737e-16  7.40148683e-17  7.40148683e-17]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.214271Z",
     "start_time": "2025-10-30T05:17:34.208351Z"
    }
   },
   "cell_type": "code",
   "source": "(np.square(1-2.333) + np.square(2-2.333) + np.square(4-2.333)) / 3",
   "id": "2ada1e452731beb6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.5555556666666668)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.230081Z",
     "start_time": "2025-10-30T05:17:34.220546Z"
    }
   },
   "cell_type": "code",
   "source": "(1-2.333) / np.sqrt(1.55555)",
   "id": "57e0078fb2d674f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-1.068779614944516)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## transform和fit_transform不同是，transform用于测试集，而且不会重新找最小值和最大值，不会重新计算均值方差",
   "id": "115a4cb2ee7925bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# 3 缺失值的处理"
   ],
   "id": "fbbfcb3a53951357"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T05:17:34.246084Z",
     "start_time": "2025-10-30T05:17:34.237189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 下面是填补，针对剩余，可以用pd和np\n",
    "def im():\n",
    "    \"\"\"\n",
    "    缺失值处理\n",
    "    :return:None \n",
    "    \"\"\"\n",
    "    # NaN,nan,缺失值必须是这种形式，如果是？号(或者其他符号)，就要replace换成这种\n",
    "    im = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    \n",
    "    data = im.fit_transform([[1, 2], [np.nan, 3], [7, 6], [3, 2]])\n",
    "    \n",
    "    print(data)\n",
    "    \n",
    "    return None\n",
    "\n",
    "im()\n",
    "print('-' * 50)\n",
    "np.nan + 10"
   ],
   "id": "455c5db9cbb66d54",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         2.        ]\n",
      " [3.66666667 3.        ]\n",
      " [7.         6.        ]\n",
      " [3.         2.        ]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
